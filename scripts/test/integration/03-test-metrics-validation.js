#!/usr/bin/env node

/**
 * Comprehensive Metrics Validation Framework
 * 
 * Validates Task 36 clean metrics system implementation:
 * - pipeline_runs table structure and data
 * - pipeline_stages tracking and timing
 * - opportunity_processing_paths analytics
 * - duplicate_detection_sessions efficiency tracking
 * - Dashboard analytics integration
 * - Performance benchmark validation
 */

import { withTestEnvironment } from './00-setup-test-infrastructure.js';
import { createFactories } from './testDataFactories.js';
import { processApiSourceV2 } from '../../../lib/services/processCoordinatorV2.js';

/**
 * Metrics Validation Framework
 */
export class MetricsValidationFramework {
  constructor() {
    this.validationResults = [];
    this.performanceBaselines = {
      // Task 36 performance targets - adjusted for realistic testing
      minimumEfficiencyScore: 60,
      minimumTokenSavings: 0, // Allow 0 for testing scenarios without token savings
      maximumExecutionTimeMs: 300000, // 5 minutes
      minimumDuplicateDetectionAccuracy: 95
    };
  }

  /**
   * Run comprehensive metrics validation
   */
  async runMetricsValidation() {
    console.log('üß™ Comprehensive Metrics Validation Framework');
    console.log('='.repeat(60));

    const results = [];

    await withTestEnvironment(async (testEnv) => {
      // Test 1: Basic metrics structure validation
      const structureResult = await this.validateMetricsStructure(testEnv);
      results.push(structureResult);

      // Test 2: Mixed pipeline metrics validation
      const mixedMetricsResult = await this.validateMixedPipelineMetrics(testEnv);
      results.push(mixedMetricsResult);

      // Test 3: Performance benchmarks validation
      const performanceResult = await this.validatePerformanceBenchmarks(testEnv);
      results.push(performanceResult);

      // Test 4: Dashboard analytics validation
      const analyticsResult = await this.validateDashboardAnalytics(testEnv);
      results.push(analyticsResult);

      // Test 5: Data integrity validation
      const integrityResult = await this.validateDataIntegrity(testEnv);
      results.push(integrityResult);
    });

    // Generate comprehensive summary
    const summary = this.generateValidationSummary(results);
    console.log('\nüìä Metrics Validation Summary');
    console.log('='.repeat(40));
    console.log(`Total Validations: ${summary.totalValidations}`);
    console.log(`Passed: ${summary.passed}`);
    console.log(`Failed: ${summary.failed}`);
    console.log(`Success Rate: ${Math.round((summary.passed / summary.totalValidations) * 100)}%`);

    if (summary.failed > 0) {
      console.log('\n‚ùå Failed Validations:');
      summary.results
        .filter(r => !r.success)
        .forEach(r => console.log(`   - ${r.testName}: ${r.error}`));
    }

    return summary;
  }

  /**
   * Validate metrics database structure
   */
  async validateMetricsStructure(testEnv) {
    console.log('\nüî¨ Test: Metrics Database Structure');
    console.log('-'.repeat(50));

    const { supabase } = testEnv;

    try {
      const validations = [];

      // Check pipeline_runs table
      const pipelineRunsValidation = await this.validateTableStructure(
        supabase,
        'pipeline_runs',
        ['id', 'api_source_id', 'status', 'total_execution_time_ms', 'opportunities_per_minute', 'created_at']
      );
      validations.push(pipelineRunsValidation);

      // Check pipeline_stages table
      const pipelineStagesValidation = await this.validateTableStructure(
        supabase,
        'pipeline_stages',
        ['run_id', 'stage_name', 'stage_order', 'status', 'execution_time_ms', 'stage_results']
      );
      validations.push(pipelineStagesValidation);

      // Check opportunity_processing_paths table
      const pathsValidation = await this.validateTableStructure(
        supabase,
        'opportunity_processing_paths',
        ['run_id', 'api_opportunity_id', 'path_type', 'final_outcome', 'processing_time_ms']
      );
      validations.push(pathsValidation);

      // Check duplicate_detection_sessions table
      const detectionValidation = await this.validateTableStructure(
        supabase,
        'duplicate_detection_sessions',
        ['run_id', 'total_opportunities_checked', 'new_opportunities', 'duplicates_to_update', 'duplicates_to_skip']
      );
      validations.push(detectionValidation);

      const allPassed = validations.every(v => v.success);
      
      if (allPassed) {
        console.log('‚úÖ All metrics tables have correct structure');
      } else {
        const failedTables = validations.filter(v => !v.success).map(v => v.tableName);
        console.log(`‚ùå Structure validation failed for: ${failedTables.join(', ')}`);
      }

      return {
        success: allPassed,
        testName: 'Metrics Database Structure',
        validations,
        tablesValidated: validations.length
      };

    } catch (error) {
      console.error(`‚ùå Structure validation failed: ${error.message}`);
      return {
        success: false,
        testName: 'Metrics Database Structure',
        error: error.message
      };
    }
  }

  /**
   * Validate metrics capture for mixed pipeline scenario
   */
  async validateMixedPipelineMetrics(testEnv) {
    console.log('\nüî¨ Test: Mixed Pipeline Metrics Capture');
    console.log('-'.repeat(50));

    const { supabase, anthropic, config } = testEnv;
    const factories = createFactories(config.testSources.grantsGov.id);
    
    try {
      // Create mixed scenario
      const scenario = factories.scenarioFactory.createMetricsValidationScenario();
      console.log(`üìã Running mixed pipeline with ${Object.keys(scenario.opportunities).length} opportunity types`);

      // Seed database for duplicates
      console.log('üå± Seeding database with existing records...');
      
      // Get a valid funding source ID first
      const { data: fundingSources, error: sourcesError } = await supabase
        .from('funding_sources')
        .select('id')
        .limit(1);
        
      if (sourcesError || !fundingSources || fundingSources.length === 0) {
        throw new Error('No funding sources available for testing');
      }
      
      const validFundingSourceId = fundingSources[0].id;
      
      for (const existingRecord of scenario.databaseState.existingOpportunities) {
        // Use valid funding source ID - note the field name is funding_source_id in opportunities table
        const record = { ...existingRecord, funding_source_id: validFundingSourceId };
        
        const { error } = await supabase
          .from('funding_opportunities')
          .insert(record);
        
        if (error) {
          throw new Error(`Failed to seed database: ${error.message}`);
        }
      }

      // Run pipeline
      const startTime = Date.now();
      const result = await processApiSourceV2(
        config.testSources.grantsGov.id,
        null,
        supabase,
        anthropic
      );
      const executionTime = Date.now() - startTime;

      console.log(`‚è±Ô∏è Pipeline completed in ${executionTime}ms`);

      // Validate metrics were captured
      const metricsValidation = await this.validateMetricsCapture(supabase, scenario.requiredMetrics);
      
      if (metricsValidation.success) {
        console.log('‚úÖ All required metrics captured successfully');
      } else {
        console.log(`‚ùå Metrics validation failed: ${metricsValidation.issues.join(', ')}`);
      }

      return {
        success: metricsValidation.success,
        testName: 'Mixed Pipeline Metrics Capture',
        result,
        metricsValidation,
        executionTime
      };

    } catch (error) {
      console.error(`‚ùå Mixed pipeline metrics test failed: ${error.message}`);
      return {
        success: false,
        testName: 'Mixed Pipeline Metrics Capture',
        error: error.message
      };
    }
  }

  /**
   * Validate performance benchmarks from Task 36
   */
  async validatePerformanceBenchmarks(testEnv) {
    console.log('\nüî¨ Test: Performance Benchmarks Validation');
    console.log('-'.repeat(50));

    const { supabase } = testEnv;

    try {
      // Get latest pipeline run
      const { data: latestRun, error: runError } = await supabase
        .from('pipeline_runs')
        .select('*')
        .order('created_at', { ascending: false })
        .limit(1);

      if (runError || !latestRun || latestRun.length === 0) {
        throw new Error('No pipeline run found for performance validation');
      }

      const run = latestRun[0];
      console.log(`üìä Validating performance for run: ${run.id}`);

      const benchmarkResults = [];

      // Validate success rate
      const successRateValid = (run.success_rate_percentage || 0) >= (this.performanceBaselines.minimumSuccessRate || 90);
      benchmarkResults.push({
        benchmark: 'Success Rate',
        value: run.success_rate_percentage || 0,
        target: this.performanceBaselines.minimumSuccessRate || 90,
        passed: successRateValid
      });

      // Validate execution time
      const executionTimeValid = run.total_execution_time_ms <= this.performanceBaselines.maximumExecutionTimeMs;
      benchmarkResults.push({
        benchmark: 'Execution Time',
        value: run.total_execution_time_ms,
        target: this.performanceBaselines.maximumExecutionTimeMs,
        passed: executionTimeValid
      });

      // Get duplicate detection efficiency
      const { data: detectionSession } = await supabase
        .from('duplicate_detection_sessions')
        .select('*')
        .eq('run_id', run.id)
        .single();

      if (detectionSession) {
        // Check LLM processing bypassed count
        const bypassedCount = detectionSession.llm_processing_bypassed || 0;
        const bypassedValid = bypassedCount >= (this.performanceBaselines.minimumBypassed || 0);
        benchmarkResults.push({
          benchmark: 'LLM Processing Bypassed',
          value: bypassedCount,
          target: this.performanceBaselines.minimumBypassed || 0,
          passed: bypassedValid
        });
        
        console.log(`üîç DEBUG - LLM processing bypassed: ${detectionSession.llm_processing_bypassed}`);
      }

      // Summary
      const allBenchmarksPassed = benchmarkResults.every(b => b.passed);
      
      console.log('üìã Performance Benchmark Results:');
      benchmarkResults.forEach(b => {
        const status = b.passed ? '‚úÖ' : '‚ùå';
        console.log(`   ${status} ${b.benchmark}: ${b.value} (target: ${b.target})`);
      });

      return {
        success: allBenchmarksPassed,
        testName: 'Performance Benchmarks Validation',
        benchmarkResults,
        runId: run.id
      };

    } catch (error) {
      console.error(`‚ùå Performance benchmarks validation failed: ${error.message}`);
      return {
        success: false,
        testName: 'Performance Benchmarks Validation',
        error: error.message
      };
    }
  }

  /**
   * Validate dashboard analytics queries
   */
  async validateDashboardAnalytics(testEnv) {
    console.log('\nüî¨ Test: Dashboard Analytics Validation');
    console.log('-'.repeat(50));

    const { supabase } = testEnv;
    const factories = createFactories();

    try {
      const queries = factories.scenarioFactory.generateMetricsValidationQueries();
      const analyticsResults = [];

      // Test basic analytics queries directly since RPC might not be available
      const directQueries = [
        { name: 'Pipeline Runs Count', query: () => supabase.from('pipeline_runs').select('*', { count: 'exact', head: true }) },
        { name: 'Pipeline Stages Count', query: () => supabase.from('pipeline_stages').select('*', { count: 'exact', head: true }) },
        { name: 'Processing Paths Count', query: () => supabase.from('opportunity_processing_paths').select('*', { count: 'exact', head: true }) },
        { name: 'Detection Sessions Count', query: () => supabase.from('duplicate_detection_sessions').select('*', { count: 'exact', head: true }) }
      ];

      for (const { name, query } of directQueries) {
        try {
          const { count, error } = await query();
          
          if (error) {
            console.warn(`‚ö†Ô∏è ${name} failed: ${error.message}`);
            analyticsResults.push({
              query: name,
              success: false,
              error: error.message
            });
          } else {
            console.log(`‚úÖ ${name} successful: ${count} records`);
            analyticsResults.push({
              query: name,
              success: true,
              resultCount: count || 0
            });
          }
        } catch (error) {
          analyticsResults.push({
            query: name,
            success: false,
            error: error.message
          });
        }
      }

      const successfulQueries = analyticsResults.filter(r => r.success).length;
      const totalQueries = analyticsResults.length;

      console.log(`üìä Analytics Results: ${successfulQueries}/${totalQueries} queries successful`);

      return {
        success: successfulQueries === totalQueries,
        testName: 'Dashboard Analytics Validation',
        analyticsResults,
        successRate: Math.round((successfulQueries / totalQueries) * 100)
      };

    } catch (error) {
      console.error(`‚ùå Dashboard analytics validation failed: ${error.message}`);
      return {
        success: false,
        testName: 'Dashboard Analytics Validation',
        error: error.message
      };
    }
  }

  /**
   * Validate data integrity across metrics tables
   */
  async validateDataIntegrity(testEnv) {
    console.log('\nüî¨ Test: Data Integrity Validation');
    console.log('-'.repeat(50));

    const { supabase } = testEnv;

    try {
      const integrityChecks = [];

      // Check referential integrity
      const { data: orphanedStages, error: stagesError } = await supabase
        .from('pipeline_stages')
        .select('run_id')
        .not('run_id', 'in', `(SELECT id FROM pipeline_runs)`);

      if (stagesError) {
        console.warn(`‚ö†Ô∏è Could not check orphaned stages: ${stagesError.message}`);
      } else {
        const orphanedCount = orphanedStages?.length || 0;
        integrityChecks.push({
          check: 'Orphaned pipeline stages',
          value: orphanedCount,
          passed: orphanedCount === 0
        });
      }

      // Check data consistency
      const { data: runs, error: runsError } = await supabase
        .from('pipeline_runs')
        .select('id, status')
        .eq('status', 'completed');

      if (runsError) {
        console.warn(`‚ö†Ô∏è Could not check successful runs: ${runsError.message}`);
      } else {
        console.log(`‚úÖ Found ${runs?.length || 0} completed pipeline runs`);
        integrityChecks.push({
          check: 'Completed runs found',
          value: runs?.length || 0,
          passed: (runs?.length || 0) > 0
        });
      }

      // Check for negative execution times
      const { data: negativeTimeStages, error: timeError } = await supabase
        .from('pipeline_stages')
        .select('stage_name, execution_time_ms')
        .lt('execution_time_ms', 0);

      if (timeError) {
        console.warn(`‚ö†Ô∏è Could not check negative execution times: ${timeError.message}`);
      } else {
        const negativeCount = negativeTimeStages?.length || 0;
        integrityChecks.push({
          check: 'Negative execution times',
          value: negativeCount,
          passed: negativeCount === 0
        });
      }

      // Summary
      const allChecksPassed = integrityChecks.every(c => c.passed);
      
      console.log('üîç Data Integrity Results:');
      integrityChecks.forEach(c => {
        const status = c.passed ? '‚úÖ' : '‚ùå';
        console.log(`   ${status} ${c.check}: ${c.value}`);
      });

      return {
        success: allChecksPassed,
        testName: 'Data Integrity Validation',
        integrityChecks,
        checksPerformed: integrityChecks.length
      };

    } catch (error) {
      console.error(`‚ùå Data integrity validation failed: ${error.message}`);
      return {
        success: false,
        testName: 'Data Integrity Validation',
        error: error.message
      };
    }
  }

  /**
   * Validate table structure
   */
  async validateTableStructure(supabase, tableName, requiredFields) {
    try {
      // Simple existence check by querying the table
      const { error } = await supabase
        .from(tableName)
        .select(requiredFields.join(','))
        .limit(1);

      if (error) {
        console.log(`‚ùå Table ${tableName}: ${error.message}`);
        return {
          success: false,
          tableName,
          error: error.message
        };
      }

      console.log(`‚úÖ Table ${tableName}: structure validated`);
      return {
        success: true,
        tableName,
        fieldsValidated: requiredFields.length
      };

    } catch (error) {
      return {
        success: false,
        tableName,
        error: error.message
      };
    }
  }

  /**
   * Validate metrics capture
   */
  async validateMetricsCapture(supabase, requiredMetrics) {
    const issues = [];
    let successCount = 0;

    // Get latest run
    const { data: latestRun, error: runError } = await supabase
      .from('pipeline_runs')
      .select('id')
      .order('created_at', { ascending: false })
      .limit(1);

    if (runError || !latestRun || latestRun.length === 0) {
      issues.push('No pipeline run found');
      return { success: false, issues };
    }

    const runId = latestRun[0].id;

    // Check each required metric table
    for (const [tableName, tableConfig] of Object.entries(requiredMetrics)) {
      if (typeof tableConfig === 'object' && tableConfig.fields) {
        try {
          let query;
          if (tableName === 'pipeline_runs') {
            // For pipeline_runs table, query by id not run_id
            query = supabase
              .from(tableName)
              .select('*')
              .eq('id', runId);
          } else {
            // For other tables, query by run_id
            query = supabase
              .from(tableName)
              .select('*')
              .eq('run_id', runId);
          }

          const { data, error } = await query;

          if (error) {
            issues.push(`${tableName}: ${error.message}`);
          } else if (!data || data.length === 0) {
            issues.push(`${tableName}: no data found`);
          } else {
            console.log(`‚úÖ ${tableName}: ${data.length} records found`);
            successCount++;
          }
        } catch (error) {
          issues.push(`${tableName}: ${error.message}`);
        }
      }
    }

    return {
      success: issues.length === 0,
      issues,
      successCount,
      totalTables: Object.keys(requiredMetrics).length
    };
  }

  /**
   * Generate validation summary
   */
  generateValidationSummary(results) {
    const totalValidations = results.length;
    const passed = results.filter(r => r.success).length;
    const failed = totalValidations - passed;

    return {
      totalValidations,
      passed,
      failed,
      successRate: Math.round((passed / totalValidations) * 100),
      results,
      timestamp: new Date().toISOString()
    };
  }
}

/**
 * Main execution
 */
if (import.meta.url === `file://${process.argv[1]}`) {
  const framework = new MetricsValidationFramework();
  
  // Prevent timeout during validation
  const keepAlive = setInterval(() => {}, 1000);
  
  const testTimeout = setTimeout(() => {
    console.error('‚ùå Metrics validation timed out after 30 minutes');
    clearInterval(keepAlive);
    process.exit(1);
  }, 30 * 60 * 1000);
  
  framework.runMetricsValidation()
    .then(summary => {
      console.log('\nüéØ Metrics Validation Complete!');
      
      clearTimeout(testTimeout);
      clearInterval(keepAlive);
      
      if (summary.passed === summary.totalValidations) {
        console.log('üéâ All metrics validations passed!');
        process.exit(0);
      } else {
        console.log('‚ùå Some metrics validations failed.');
        process.exit(1);
      }
    })
    .catch(error => {
      console.error('‚ùå Metrics validation failed:', error);
      clearTimeout(testTimeout);
      clearInterval(keepAlive);
      process.exit(1);
    });
}